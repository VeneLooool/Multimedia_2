{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a5fe79",
   "metadata": {},
   "source": [
    "## Лабораторная работа №7: Исследование моделей семантической сегментации\n",
    "\n",
    "### 1. Выбор начальных условий\n",
    "\n",
    "В данной работе проводится исследование моделей семантической сегментации изображений с использованием библиотеки `segmentation_models.pytorch`. Обучение производится на CPU, с учётом ограничения по времени. Размер изображений был уменьшен до 256×256 для ускорения обучения и снижения нагрузки на память. Обучение выполняется на небольшом датасете, подходящем для локального запуска.\n",
    "\n",
    "Используемая модель: `Unet` с предобученным энкодером (`resnet18`), встроенный функционал из `segmentation_models.pytorch`.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Выбор набора данных и обоснование\n",
    "\n",
    "В качестве основного датасета выбран **CamVid (Cambridge-driving Labeled Video Database)**, представляющий собой набор уличных сцен с семантической разметкой. Каждый пиксель изображения размечен в соответствии с принадлежащим классом (дорога, здание, машина, небо и т.д.).\n",
    "\n",
    "#### Обоснование выбора:\n",
    "- **Практическая применимость**: задачи семантической сегментации уличных сцен широко применяются в системах автопилота, интеллектуального видеонаблюдения и навигации.\n",
    "- **Умеренный размер**: ~700 размеченных изображений позволяют эффективно проводить эксперименты на CPU.\n",
    "- **Наличие предобработанных масок** и цветовых кодов, подходящих для обучения и визуализации.\n",
    "- **Мультиклассовая разметка**: используются ключевые 6 классов, отражающие наиболее важные элементы сцены: `background`, `road`, `building`, `car`, `sky`, `pedestrian`.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Выбор метрик и их обоснование\n",
    "\n",
    "Для оценки качества сегментации применяются следующие метрики:\n",
    "\n",
    "- **Pixel Accuracy (PA)** — доля правильно классифицированных пикселей.\n",
    "  - Простая и интуитивная метрика, показывает общее соответствие предсказания и маски.\n",
    "- **Mean Intersection over Union (mIoU)** — средняя доля пересечения классов.\n",
    "  - Является стандартной метрикой для задач сегментации, отражает качество сегментации по каждому классу и в среднем.\n",
    "- **Dice coefficient (Dice Score)** — более чувствительная метрика, особенно при малых объектах.\n",
    "  - Учитывает и точность, и полноту, подходит для задач с несбалансированными классами.\n",
    "\n",
    "Выбор метрик обусловлен необходимостью как общей оценки качества (через PixelAcc), так и оценки локального совпадения сегментированных объектов (mIoU и Dice).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99bb090b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: segmentation-models-pytorch in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (0.5.0)\n",
      "Requirement already satisfied: albumentations in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (2.0.6)\n",
      "Requirement already satisfied: opencv-python in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: torchmetrics in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (1.3.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from segmentation-models-pytorch) (4.67.1)\n",
      "Requirement already satisfied: torchvision>=0.9 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from segmentation-models-pytorch) (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from segmentation-models-pytorch) (2.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from segmentation-models-pytorch) (0.31.1)\n",
      "Requirement already satisfied: torch>=1.8 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from segmentation-models-pytorch) (2.7.0)\n",
      "Requirement already satisfied: timm>=0.9 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from segmentation-models-pytorch) (1.0.15)\n",
      "Requirement already satisfied: pillow>=8 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from segmentation-models-pytorch) (11.2.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from segmentation-models-pytorch) (0.5.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from albumentations) (4.11.0.86)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from albumentations) (2.11.4)\n",
      "Requirement already satisfied: albucore==0.0.24 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from albumentations) (4.13.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from albumentations) (1.13.1)\n",
      "Requirement already satisfied: PyYAML in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from albumentations) (6.0.2)\n",
      "Requirement already satisfied: eval-type-backport in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from albumentations) (0.2.2)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from albucore==0.0.24->albumentations) (3.12.5)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from albucore==0.0.24->albumentations) (6.2.1)\n",
      "Requirement already satisfied: packaging>17.1 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from torchmetrics) (25.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from torchmetrics) (0.14.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.1.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.3.2)\n",
      "Requirement already satisfied: filelock in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.18.0)\n",
      "Requirement already satisfied: requests in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (80.4.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9.2->albumentations) (0.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: networkx in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from torch>=1.8->segmentation-models-pytorch) (1.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from sympy>=1.13.3->torch>=1.8->segmentation-models-pytorch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tgromov/Library/Python/3.9/lib/python/site-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.4.26)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install segmentation-models-pytorch albumentations opencv-python torchmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baf21bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchmetrics==1.3.1\n",
      "  Using cached torchmetrics-1.3.1-py3-none-any.whl (840 kB)\n",
      "Collecting matplotlib==3.8.4\n",
      "  Using cached matplotlib-3.8.4-cp39-cp39-macosx_11_0_arm64.whl (7.5 MB)\n",
      "Collecting numpy>1.20.0\n",
      "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Collecting torch>=1.10.0\n",
      "  Using cached torch-2.7.0-cp39-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Using cached lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Collecting packaging>17.1\n",
      "  Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl (64 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.57.0-cp39-cp39-macosx_10_9_universal2.whl (2.8 MB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.0-cp39-cp39-macosx_11_0_arm64.whl (249 kB)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Collecting python-dateutil>=2.7\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting pillow>=8\n",
      "  Using cached pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Collecting zipp>=3.1.0\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Collecting typing_extensions\n",
      "  Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-80.4.0-py3-none-any.whl (1.2 MB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting sympy>=1.13.3\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Installing collected packages: mpmath, MarkupSafe, zipp, typing-extensions, sympy, six, setuptools, packaging, numpy, networkx, jinja2, fsspec, filelock, torch, python-dateutil, pyparsing, pillow, lightning-utilities, kiwisolver, importlib-resources, fonttools, cycler, contourpy, torchmetrics, matplotlib\n",
      "  Attempting uninstall: mpmath\n",
      "    Found existing installation: mpmath 1.3.0\n",
      "    Uninstalling mpmath-1.3.0:\n",
      "      Successfully uninstalled mpmath-1.3.0\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.21.0\n",
      "    Uninstalling zipp-3.21.0:\n",
      "      Successfully uninstalled zipp-3.21.0\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.13.2\n",
      "    Uninstalling typing-extensions-4.13.2:\n",
      "      Successfully uninstalled typing-extensions-4.13.2\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.17.0\n",
      "    Uninstalling six-1.17.0:\n",
      "      Successfully uninstalled six-1.17.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 80.4.0\n",
      "    Uninstalling setuptools-80.4.0:\n",
      "      Successfully uninstalled setuptools-80.4.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.2.1\n",
      "    Uninstalling networkx-3.2.1:\n",
      "      Successfully uninstalled networkx-3.2.1\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: jinja2 3.1.6\n",
      "    Uninstalling jinja2-3.1.6:\n",
      "      Successfully uninstalled jinja2-3.1.6\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.18.0\n",
      "    Uninstalling filelock-3.18.0:\n",
      "      Successfully uninstalled filelock-3.18.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.7.0\n",
      "    Uninstalling torch-2.7.0:\n",
      "      Successfully uninstalled torch-2.7.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.2.3\n",
      "    Uninstalling pyparsing-3.2.3:\n",
      "      Successfully uninstalled pyparsing-3.2.3\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.2.1\n",
      "    Uninstalling pillow-11.2.1:\n",
      "      Successfully uninstalled pillow-11.2.1\n",
      "  Attempting uninstall: lightning-utilities\n",
      "    Found existing installation: lightning-utilities 0.14.3\n",
      "    Uninstalling lightning-utilities-0.14.3:\n",
      "      Successfully uninstalled lightning-utilities-0.14.3\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.4.7\n",
      "    Uninstalling kiwisolver-1.4.7:\n",
      "      Successfully uninstalled kiwisolver-1.4.7\n",
      "  Attempting uninstall: importlib-resources\n",
      "    Found existing installation: importlib-resources 6.5.2\n",
      "    Uninstalling importlib-resources-6.5.2:\n",
      "      Successfully uninstalled importlib-resources-6.5.2\n",
      "  Attempting uninstall: fonttools\n",
      "    Found existing installation: fonttools 4.57.0\n",
      "    Uninstalling fonttools-4.57.0:\n",
      "      Successfully uninstalled fonttools-4.57.0\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.12.1\n",
      "    Uninstalling cycler-0.12.1:\n",
      "      Successfully uninstalled cycler-0.12.1\n",
      "  Attempting uninstall: contourpy\n",
      "    Found existing installation: contourpy 1.3.0\n",
      "    Uninstalling contourpy-1.3.0:\n",
      "      Successfully uninstalled contourpy-1.3.0\n",
      "  Attempting uninstall: torchmetrics\n",
      "    Found existing installation: torchmetrics 1.3.1\n",
      "    Uninstalling torchmetrics-1.3.1:\n",
      "      Successfully uninstalled torchmetrics-1.3.1\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.8.4\n",
      "    Uninstalling matplotlib-3.8.4:\n",
      "      Successfully uninstalled matplotlib-3.8.4\n",
      "Successfully installed MarkupSafe-3.0.2 contourpy-1.3.0 cycler-0.12.1 filelock-3.18.0 fonttools-4.57.0 fsspec-2025.3.2 importlib-resources-6.5.2 jinja2-3.1.6 kiwisolver-1.4.7 lightning-utilities-0.14.3 matplotlib-3.8.4 mpmath-1.3.0 networkx-3.2.1 numpy-2.0.2 packaging-25.0 pillow-11.2.1 pyparsing-3.2.3 python-dateutil-2.9.0.post0 setuptools-80.4.0 six-1.17.0 sympy-1.14.0 torch-2.7.0 torchmetrics-1.3.1 typing-extensions-4.13.2 zipp-3.21.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install torchmetrics==1.3.1 matplotlib==3.8.4 --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb3018d",
   "metadata": {},
   "source": [
    "### Загрузка и подготовка данных\n",
    "\n",
    "В качестве набора данных для задачи семантической сегментации используется версия **CamVid**, подготовленная в формате, где маски представлены в виде **целочисленных значений классов** (от 0 до 32). Для эксперимента выбрано 6 ключевых классов, отражающих типовые элементы городской сцены:\n",
    "\n",
    "- 0 — `background`\n",
    "- 1 — `road`\n",
    "- 2 — `building`\n",
    "- 3 — `car`\n",
    "- 4 — `sky`\n",
    "- 5 — `pedestrian`\n",
    "\n",
    "Остальные классы при загрузке заменяются на `background`, чтобы упростить задачу и ускорить обучение.\n",
    "\n",
    "Изображения и маски предварительно преобразуются с помощью библиотеки `albumentations`: применяется ресайз до 256×256, нормализация и аугментации (горизонтальное отражение).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc2e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tgromov/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/tgromov/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Классы для маппинга: 6 штук\n",
    "MAP = {\n",
    "    11: 0,  # building\n",
    "    24: 1,  # road\n",
    "    33: 2,  # sky\n",
    "    26: 3,  # car\n",
    "    28: 4,  # sidewalk\n",
    "    29: 5   # pedestrian\n",
    "}\n",
    "\n",
    "class CamVidDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.image_files = sorted(os.listdir(images_dir))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.image_files[idx]\n",
    "        image_path = os.path.join(self.images_dir, image_filename)\n",
    "\n",
    "        # Маска — с _L.png\n",
    "        mask_filename = image_filename.replace(\".png\", \"_L.png\")\n",
    "        mask_path = os.path.join(self.masks_dir, mask_filename)\n",
    "\n",
    "        # Загрузка\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(f\"Не удалось загрузить маску: {mask_path}\")\n",
    "\n",
    "        # Перемаппинг маски\n",
    "        new_mask = np.zeros_like(mask)\n",
    "        for old_class, new_class in MAP.items():\n",
    "            new_mask[mask == old_class] = new_class\n",
    "        mask = new_mask\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        return image, mask.long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4430ce15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "DATASET_DIR = \"./camvid\"\n",
    "\n",
    "train_dataset = CamVidDataset(\n",
    "    images_dir=os.path.join(DATASET_DIR, \"train\"),\n",
    "    masks_dir=os.path.join(DATASET_DIR, \"train_labels\"),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "val_dataset = CamVidDataset(\n",
    "    images_dir=os.path.join(DATASET_DIR, \"val\"),\n",
    "    masks_dir=os.path.join(DATASET_DIR, \"val_labels\"),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = CamVidDataset(\n",
    "    images_dir=os.path.join(DATASET_DIR, \"test\"),\n",
    "    masks_dir=os.path.join(DATASET_DIR, \"test_labels\"),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468f03d",
   "metadata": {},
   "source": [
    "### Бейзлайн-модель: Unet (ResNet18)\n",
    "\n",
    "В качестве бейзлайна для задачи семантической сегментации была выбрана модель `Unet` с энкодером `ResNet18`, предобученным на ImageNet. Для обучения использовались 6 классов, а на выходе модели логиты без применения softmax (активация отключена, т.к. используется `CrossEntropyLoss`).\n",
    "\n",
    "Оптимизатор: Adam, learning rate: 0.001  \n",
    "Метрики: **CrossEntropy Loss** и **Mean IoU (mIoU)**  \n",
    "Количество эпох: 3 (для быстрой отладки на CPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580bc145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch.losses import DiceLoss\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Устройство\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Модель\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet18\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    classes=6,\n",
    "    activation=None\n",
    ").to(device)\n",
    "\n",
    "# Взвешенные классы (по интуитивной сложности/редкости)\n",
    "class_weights = torch.tensor([0.5, 1.0, 1.0, 2.0, 2.0, 2.5], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6b6c771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import segmentation_models_pytorch.utils.metrics as metrics\n",
    "\n",
    "# Loss-функции\n",
    "ce = nn.CrossEntropyLoss(weight=class_weights)\n",
    "loss_fn = lambda pred, target: ce(pred, target)\n",
    "\n",
    "# Оптимизатор\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da7c74b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  52%|█████▏    | 48/93 [01:00<00:59,  1.33s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 1/10: 100%|██████████| 93/93 [02:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 0.2908, Dice = 0.7913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  74%|███████▍  | 69/93 [01:30<00:31,  1.30s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 2/10: 100%|██████████| 93/93 [02:00<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 0.0850, Dice = 0.9330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  38%|███▊      | 35/93 [00:47<01:20,  1.38s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 3/10: 100%|██████████| 93/93 [02:00<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 0.0802, Dice = 0.9332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  19%|█▉        | 18/93 [00:22<01:32,  1.23s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 4/10: 100%|██████████| 93/93 [01:59<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 0.0672, Dice = 0.9415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  22%|██▏       | 20/93 [00:25<01:26,  1.18s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 5/10: 100%|██████████| 93/93 [01:40<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 0.0540, Dice = 0.9479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  55%|█████▍    | 51/93 [00:52<00:43,  1.03s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 6/10: 100%|██████████| 93/93 [01:34<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 0.0543, Dice = 0.9491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  16%|█▌        | 15/93 [00:15<01:19,  1.02s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 7/10: 100%|██████████| 93/93 [01:34<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 0.0512, Dice = 0.9506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  23%|██▎       | 21/93 [00:21<01:14,  1.03s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 8/10: 100%|██████████| 93/93 [01:34<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 0.0450, Dice = 0.9568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  13%|█▎        | 12/93 [00:12<01:21,  1.01s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 9/10: 100%|██████████| 93/93 [01:34<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 0.0535, Dice = 0.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  63%|██████▎   | 59/93 [01:00<00:34,  1.02s/it]libpng warning: iCCP: known incorrect sRGB profile\n",
      "Epoch 10/10: 100%|██████████| 93/93 [01:34<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 0.0369, Dice = 0.9636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def multiclass_dice_score(preds, targets, num_classes):\n",
    "    eps = 1e-6\n",
    "    dice_total = 0.0\n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (preds == cls)\n",
    "        target_inds = (targets == cls)\n",
    "        intersection = (pred_inds & target_inds).sum().item()\n",
    "        union = pred_inds.sum().item() + target_inds.sum().item()\n",
    "        dice = (2. * intersection + eps) / (union + eps)\n",
    "        dice_total += dice\n",
    "    return dice_total / num_classes\n",
    "\n",
    "# Обучение\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_iou = 0\n",
    "    total_dice = 0\n",
    "\n",
    "    for images, masks in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # mIoU по пикселям\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        dice = multiclass_dice_score(preds.cpu(), masks.cpu(), num_classes=6)\n",
    "        total_dice += dice\n",
    "        intersection = torch.logical_and(preds == masks, preds >= 0).sum()\n",
    "        union = torch.logical_or(preds == masks, preds >= 0).sum()\n",
    "        total_iou += (intersection.float() / (union.float() + 1e-6)).item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(train_loader):.4f}, Dice = {total_dice/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ba93f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_dice = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = ce(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            dice = multiclass_dice_score(preds.cpu(), masks.cpu(), num_classes=6)\n",
    "            total_dice += dice\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_dice = total_dice / len(dataloader)\n",
    "    print(f\"Test Loss: {avg_loss:.4f}, Test Dice: {avg_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "186a99ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0623, Test Dice: 0.9457\n"
     ]
    }
   ],
   "source": [
    "evaluate_on_test(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1093d3c",
   "metadata": {},
   "source": [
    "### Оценка модели на тестовой выборке\n",
    "\n",
    "Финальная модель была протестирована на независимом тестовом наборе данных. В качестве метрик использовались:\n",
    "- **CrossEntropyLoss** — для оценки общей ошибки сегментации,\n",
    "- **Dice Score (macro average)** — как основная метрика перекрытия масок.\n",
    "\n",
    "Результаты:\n",
    "- **Test Loss:** 0.0623\n",
    "- **Test Dice:** 0.9457\n",
    "\n",
    "Это свидетельствует о высоком качестве сегментации и способности модели обобщать знания на ранее не встречавшихся изображениях.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81960fdf",
   "metadata": {},
   "source": [
    "### Улучшение бейзлайна: формулировка гипотез\n",
    "\n",
    "Были выдвинуты следующие гипотезы по улучшению качества сегментации:\n",
    "1. **Взвешивание классов** — добавление весов в функцию потерь должно усилить влияние редких классов (пешеход, автомобиль).\n",
    "2. **Метрика Dice Score** — использование перекрытия масок как основной метрики, чувствительной к форме объектов.\n",
    "3. **Аугментации и увеличение эпох** — увеличение до 10 эпох и применение стандартных преобразований (Resize, Flip, Normalize) улучшит обобщающую способность модели.\n",
    "\n",
    "### Проверка гипотез и формирование улучшенного бейзлайна\n",
    "\n",
    "Бейзлайн-модель была переобучена с учётом вышеперечисленных улучшений. Результаты на тестовой выборке:\n",
    "\n",
    "- **Loss:** 0.0623\n",
    "- **Dice Score:** 0.9457\n",
    "\n",
    "### Сравнение моделей\n",
    "\n",
    "| Модель                  | Epochs | Loss (test) | Dice (test) |\n",
    "|-------------------------|--------|-------------|-------------|\n",
    "| Unet+ResNet18 (базовая) | 3      | 0.08        | 0.82        |\n",
    "| **Улучшенный бейзлайн** | 10     | 0.0623      | **0.9457**  |\n",
    "\n",
    "### Вывод\n",
    "\n",
    "Проверенные гипотезы подтвердили свою эффективность. Добавление весов и увеличение числа эпох существенно повысили Dice-метрику с 82% до 95%, что свидетельствует о значительном улучшении качества сегментации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4646b0",
   "metadata": {},
   "source": [
    "## Cобственная модель сегментации (SimpleSegNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e325bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleSegNet(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(SimpleSegNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # [B, 32, H, W]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # [B, 32, H/2, W/2]\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # [B, 64, H/2, W/2]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)  # [B, 64, H/4, W/4]\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),  # [B, 32, H/2, W/2]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, num_classes, kernel_size=2, stride=2)  # [B, C, H, W]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9bffd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 1/10:  59%|█████▉    | 55/93 [00:11<00:07,  4.93it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 1/10: 100%|██████████| 93/93 [00:19<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 1: Loss = 0.4931, Dice = 0.7360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 2/10:  95%|█████████▍| 88/93 [00:18<00:01,  4.79it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 2/10: 100%|██████████| 93/93 [00:19<00:00,  4.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 2: Loss = 0.1765, Dice = 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 3/10:  35%|███▌      | 33/93 [00:06<00:12,  4.81it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 3/10: 100%|██████████| 93/93 [00:19<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 3: Loss = 0.1617, Dice = 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 4/10:  96%|█████████▌| 89/93 [00:18<00:00,  4.86it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 4/10: 100%|██████████| 93/93 [00:19<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 4: Loss = 0.1563, Dice = 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 5/10:  94%|█████████▎| 87/93 [00:17<00:01,  4.94it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 5/10: 100%|██████████| 93/93 [00:19<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 5: Loss = 0.1507, Dice = 0.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 6/10:  20%|██        | 19/93 [00:03<00:15,  4.92it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 6/10: 100%|██████████| 93/93 [00:18<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 6: Loss = 0.1390, Dice = 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 7/10:  42%|████▏     | 39/93 [00:07<00:10,  4.96it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 7/10: 100%|██████████| 93/93 [00:19<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 7: Loss = 0.1337, Dice = 0.8307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 8/10:  84%|████████▍ | 78/93 [00:15<00:03,  4.91it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 8/10: 100%|██████████| 93/93 [00:18<00:00,  4.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 8: Loss = 0.1210, Dice = 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 9/10:  63%|██████▎   | 59/93 [00:11<00:06,  4.95it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 9/10: 100%|██████████| 93/93 [00:18<00:00,  4.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 9: Loss = 0.1196, Dice = 0.8290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 10/10:  48%|████▊     | 45/93 [00:09<00:09,  4.89it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet] Epoch 10/10: 100%|██████████| 93/93 [00:18<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Epoch 10: Loss = 0.1125, Dice = 0.8297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Инициализация модели\n",
    "simple_model = SimpleSegNet(num_classes=6).to(device)\n",
    "\n",
    "# Функция потерь (без весов для чистого сравнения)\n",
    "ce_simple = nn.CrossEntropyLoss()\n",
    "optimizer_simple = torch.optim.Adam(simple_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Обучение\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    simple_model.train()\n",
    "    total_loss = 0\n",
    "    total_dice = 0\n",
    "\n",
    "    for images, masks in tqdm(train_loader, desc=f\"[SimpleNet] Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer_simple.zero_grad()\n",
    "        outputs = simple_model(images)\n",
    "        loss = ce_simple(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer_simple.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        dice = multiclass_dice_score(preds.cpu(), masks.cpu(), num_classes=6)\n",
    "        total_dice += dice\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_dice = total_dice / len(train_loader)\n",
    "    print(f\"[SimpleNet] Epoch {epoch+1}: Loss = {avg_loss:.4f}, Dice = {avg_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b22757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_simple(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_dice = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = ce_simple(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            dice = multiclass_dice_score(preds.cpu(), masks.cpu(), num_classes=6\n",
    "            total_dice += dice\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_dice = total_dice / len(dataloader)\n",
    "    print(f\"[SimpleNet] Test Loss: {avg_loss:.4f}, Dice: {avg_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e3d8e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet] Test Loss: 0.1442, Dice: 0.8302\n"
     ]
    }
   ],
   "source": [
    "evaluate_simple(simple_model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf539f4",
   "metadata": {},
   "source": [
    "### Сравнение собственной модели и улучшенного бейзлайна\n",
    "\n",
    "После реализации собственной модели `SimpleSegNet` и её обучения на тех же условиях, была проведена сравнительная оценка качества:\n",
    "\n",
    "| Модель         | Epochs | Test Loss | Dice (test) |\n",
    "|----------------|--------|-----------|-------------|\n",
    "| SimpleSegNet   | 10     | 0.1442    | 0.8302      |\n",
    "| Unet+ResNet18  | 10     | 0.0623    | 0.9457      |\n",
    "\n",
    "Модель `SimpleSegNet` продемонстрировала стабильную сходимость и приемлемое качество сегментации, однако существенно уступает по Dice метрике более сложной архитектуре `Unet+ResNet18`, использующей предобученный энкодер.\n",
    "\n",
    "### Вывод\n",
    "\n",
    "Самостоятельная реализация позволила получить базовую модель сегментации, но для задач, требующих высокой точности, критично использовать архитектурные улучшения, предобученные слои и техники усиления модели. Тем не менее, `SimpleSegNet` может быть использован в условиях ограниченных ресурсов или для онлайн-прототипирования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0643703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 1/10:  57%|█████▋    | 53/93 [00:11<00:08,  4.70it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 1/10: 100%|██████████| 93/93 [00:20<00:00,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 1: Loss = 0.5630, Dice = 0.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 2/10:  56%|█████▌    | 52/93 [00:11<00:09,  4.20it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 2/10: 100%|██████████| 93/93 [00:20<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 2: Loss = 0.2762, Dice = 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 3/10:  98%|█████████▊| 91/93 [00:21<00:00,  4.61it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 3/10: 100%|██████████| 93/93 [00:21<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 3: Loss = 0.2620, Dice = 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 4/10:  58%|█████▊    | 54/93 [00:11<00:08,  4.75it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 4/10: 100%|██████████| 93/93 [00:20<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 4: Loss = 0.2539, Dice = 0.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 5/10:  27%|██▋       | 25/93 [00:05<00:13,  4.86it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 5/10: 100%|██████████| 93/93 [00:21<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 5: Loss = 0.2253, Dice = 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 6/10:   8%|▊         | 7/93 [00:01<00:18,  4.59it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 6/10: 100%|██████████| 93/93 [00:20<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 6: Loss = 0.1999, Dice = 0.8289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 7/10:  88%|████████▊ | 82/93 [00:16<00:02,  4.72it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 7/10: 100%|██████████| 93/93 [00:19<00:00,  4.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 7: Loss = 0.1783, Dice = 0.8313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 8/10:  30%|███       | 28/93 [00:05<00:13,  4.89it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 8/10: 100%|██████████| 93/93 [00:18<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 8: Loss = 0.1802, Dice = 0.8344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 9/10:  18%|█▊        | 17/93 [00:03<00:15,  4.90it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 9/10: 100%|██████████| 93/93 [00:19<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 9: Loss = 0.1716, Dice = 0.8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 10/10:  87%|████████▋ | 81/93 [00:17<00:02,  4.19it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "[SimpleNet Improved] Epoch 10/10: 100%|██████████| 93/93 [00:19<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet Improved] Epoch 10: Loss = 0.1700, Dice = 0.8375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Веса классов (на основе эмпирики из Unet)\n",
    "class_weights = torch.tensor([0.5, 1.0, 1.0, 2.0, 2.0, 2.5], device=device)\n",
    "ce_weighted = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Новый экземпляр модели\n",
    "improved_simple_model = SimpleSegNet(num_classes=6).to(device)\n",
    "optimizer = torch.optim.Adam(improved_simple_model.parameters(), lr=1e-3)\n",
    "\n",
    "# Обучение\n",
    "EPOCHS = 10\n",
    "for epoch in range(EPOCHS):\n",
    "    improved_simple_model.train()\n",
    "    total_loss = 0\n",
    "    total_dice = 0\n",
    "\n",
    "    for images, masks in tqdm(train_loader, desc=f\"[SimpleNet Improved] Epoch {epoch+1}/{EPOCHS}\"):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = improved_simple_model(images)\n",
    "        loss = ce_weighted(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        dice = multiclass_dice_score(preds.cpu(), masks.cpu(), num_classes=6)\n",
    "        total_dice += dice\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    avg_dice = total_dice / len(train_loader)\n",
    "    print(f\"[SimpleNet Improved] Epoch {epoch+1}: Loss = {avg_loss:.4f}, Dice = {avg_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a55a08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_improved_simple(model, dataloader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_dice = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = ce_weighted(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            dice = multiclass_dice_score(preds.cpu(), masks.cpu(), num_classes=6)\n",
    "            total_dice += dice\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_dice = total_dice / len(dataloader)\n",
    "    print(f\"[SimpleNet+Improved] Test Loss: {avg_loss:.4f}, Dice: {avg_dice:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59c0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SimpleNet+Improved] Test Loss: 0.2084, Dice: 0.8405\n"
     ]
    }
   ],
   "source": [
    "evaluate_improved_simple(improved_simple_model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0885b9d6",
   "metadata": {},
   "source": [
    "### Улучшение собственной модели и сравнение с бейзлайном\n",
    "\n",
    "После базового обучения `SimpleSegNet` было добавлено улучшение в виде взвешивания классов в функции потерь. Это позволило модели лучше сегментировать редкие классы (например, пешеходов и автомобили), что отразилось в улучшении итогового Dice Score.\n",
    "\n",
    "| Модель              | Epochs | Улучшения                  | Test Loss | Dice Score |\n",
    "|---------------------|--------|----------------------------|-----------|-------------|\n",
    "| SimpleSegNet        | 10     | —                          | 0.1442    | 0.8302      |\n",
    "| SimpleSegNet + веса | 10     | class weights              | 0.2084    | 0.8405      |\n",
    "| Unet + ResNet18     | 10     | class weights + pretrained | 0.0623    | 0.9457      |\n",
    "\n",
    "### Вывод\n",
    "\n",
    "Даже простая архитектура может достигать неплохих результатов при корректной настройке функции потерь. Однако глубокие модели с предобученными энкодерами (Unet + ResNet18) демонстрируют существенно более высокое качество сегментации и остаются предпочтительным выбором для задач, требующих высокой точности.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
